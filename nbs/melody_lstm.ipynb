{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jazz melody generation using LSTMs\n",
    "\n",
    "Using data from the Weimar Jazz Database and based on Jason Brownlee's LSTM text generation tutorial.\n",
    "\n",
    "Currently this only takes in a single MIDI file containing the melody track; further notebooks will explore multiple MIDI files, harmony mappings, and who knows what else!\n",
    "\n",
    "Audio links are at the very bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import re\n",
    "\n",
    "import h5py\n",
    "import keras\n",
    "import mido\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name of the tune we're loading in; should match MIDI file name\n",
    "#tune_name = \"ArtPepper_Anthropology_FINAL\"\n",
    "tune_name = \"ColemanHawkins_BodyAndSoul_FINAL\"\n",
    "# tune_name = \"JohnColtrane_Oleo_FINAL\"\n",
    "# tune_name = \"MilesDavis_Oleo-1_FINAL\"\n",
    "# tune_name = \"RedGarland_Oleo_FINAL\"\n",
    "\n",
    "# Whether or not to fit the model (or to use existing weights)\n",
    "should_fit_model = False # Change this to True if we want to fit the model, False to skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# midi_file = mido.MidiFile(\"../data/midi/{}.mid\".format(tune_name)) # Unquantized\n",
    "midi_file = mido.MidiFile(\"../data/midi_quantized/{}.mid\".format(tune_name)) # Quantized\n",
    "midi_track = midi_file.tracks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<message note_on channel=0 note=51 velocity=100 time=76230>,\n",
       " <message note_off channel=0 note=51 velocity=100 time=16170>,\n",
       " <message note_on channel=0 note=51 velocity=96 time=0>,\n",
       " <message note_off channel=0 note=51 velocity=96 time=9240>,\n",
       " <message note_on channel=0 note=51 velocity=94 time=0>,\n",
       " <message note_off channel=0 note=51 velocity=94 time=43890>,\n",
       " <message note_on channel=0 note=51 velocity=104 time=0>,\n",
       " <message note_off channel=0 note=51 velocity=104 time=6930>,\n",
       " <message note_on channel=0 note=53 velocity=99 time=0>,\n",
       " <message note_off channel=0 note=53 velocity=99 time=6930>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get notes only\n",
    "midi_notes = [msg for msg in midi_track if msg.type==\"note_on\" or msg.type==\"note_off\"]\n",
    "len(midi_notes)\n",
    "midi_notes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len([msg for msg in midi_track if msg.type==\"note_on\" and msg.time>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create note on/off pairs\n",
    "midi_note_pairs = [(midi_notes[i], midi_notes[i+1]) for i,_ in enumerate(midi_notes[:-1])\n",
    "                    if midi_notes[i].type==\"note_on\" and midi_notes[i+1].type==\"note_off\"\n",
    "                    and midi_notes[i].note == midi_notes[i+1].note]\n",
    "len(midi_note_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 60, 70, 80, 90, 100, 110, 120}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize note velocities\n",
    "# TODO: Play with normalizing other parameters\n",
    "for note_on, note_off in midi_note_pairs:\n",
    "    note_on.velocity = note_on.velocity - (note_on.velocity % 10)\n",
    "set([note_on.velocity for note_on, note_off in midi_note_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<message note_on channel=0 note=51 velocity=100 time=76230>,\n",
       "  <message note_off channel=0 note=51 velocity=100 time=16170>),\n",
       " (<message note_on channel=0 note=51 velocity=90 time=0>,\n",
       "  <message note_off channel=0 note=51 velocity=96 time=9240>),\n",
       " (<message note_on channel=0 note=51 velocity=90 time=0>,\n",
       "  <message note_off channel=0 note=51 velocity=94 time=43890>),\n",
       " (<message note_on channel=0 note=51 velocity=100 time=0>,\n",
       "  <message note_off channel=0 note=51 velocity=104 time=6930>),\n",
       " (<message note_on channel=0 note=53 velocity=90 time=0>,\n",
       "  <message note_off channel=0 note=53 velocity=99 time=6930>),\n",
       " (<message note_on channel=0 note=54 velocity=110 time=0>,\n",
       "  <message note_off channel=0 note=54 velocity=111 time=6930>),\n",
       " (<message note_on channel=0 note=53 velocity=100 time=0>,\n",
       "  <message note_off channel=0 note=53 velocity=108 time=4620>),\n",
       " (<message note_on channel=0 note=54 velocity=100 time=0>,\n",
       "  <message note_off channel=0 note=54 velocity=108 time=4620>),\n",
       " (<message note_on channel=0 note=53 velocity=90 time=0>,\n",
       "  <message note_off channel=0 note=53 velocity=97 time=39270>),\n",
       " (<message note_on channel=0 note=51 velocity=90 time=0>,\n",
       "  <message note_off channel=0 note=51 velocity=96 time=13860>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_note_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 unique notes in note set (vs. 635 note events in MIDI file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(46, 100, 0, 27720),\n",
       " (48, 80, 0, 6930),\n",
       " (48, 90, 0, 6930),\n",
       " (48, 90, 0, 13860),\n",
       " (48, 100, 0, 6930),\n",
       " (48, 100, 0, 9240),\n",
       " (48, 100, 0, 16170),\n",
       " (48, 100, 0, 23100),\n",
       " (49, 80, 0, 6930),\n",
       " (49, 80, 0, 7919)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create note set\n",
    "# note_events_keys = (\"type\", \"pitch\", \"velocity\", \"duration\")\n",
    "# note_events = [(note.type, note.note, note.velocity, note.time) for note in midi_notes]\n",
    "\n",
    "note_events_keys = (\"noteon_pitch\", \"noteon_velocity\", \"noteon_time\", \"noteoff_time\") # Don't use note off velocity to shrink possibilities, and don't use note off pitch because it's the same as note on pitch\n",
    "note_events = [(note_on.note, note_on.velocity, note_on.time, note_off.time)\n",
    "               for note_on, note_off in midi_note_pairs]\n",
    "\n",
    "note_set = sorted(list(set(note_events)))\n",
    "num_note_events = len(note_events)\n",
    "num_unique_notes = len(note_set)\n",
    "print(\"{} unique notes in note set (vs. {} note events in MIDI file)\".format(num_unique_notes, num_note_events))\n",
    "note_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len([note for note in note_set if note[0] == \"note_off\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(65, 100, 0, 18480): 321}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make map for note to integer\n",
    "note_to_int = dict((n, i) for i, n in enumerate(note_set))\n",
    "{list(note_to_int.keys())[0]: note_to_int[list(note_to_int.keys())[0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (46, 100, 0, 27720)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make map for integer back to note (we'll need this in the generation phase)\n",
    "int_to_note = dict((i, n) for i, n in enumerate(note_set))\n",
    "{list(int_to_note.keys())[0]: int_to_note[list(int_to_note.keys())[0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625 sequences\n",
      "[47, 41, 43, 45, 74, 109, 80, 98, 78, 42] ==> 193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[47, 41, 43, 45, 74, 109, 80, 98, 78, 42],\n",
       " [41, 43, 45, 74, 109, 80, 98, 78, 42, 193],\n",
       " [43, 45, 74, 109, 80, 98, 78, 42, 193, 194],\n",
       " [45, 74, 109, 80, 98, 78, 42, 193, 194, 185],\n",
       " [74, 109, 80, 98, 78, 42, 193, 194, 185, 26]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into subsequences\n",
    "# TODO: Play with sequence lengths (for both input and outputs)\n",
    "seq_length = 10\n",
    "data_input = [] # \"X\"\n",
    "data_output = [] # \"y\"\n",
    "for i in range(num_note_events-seq_length):\n",
    "    seq_input = note_events[i:i+seq_length]\n",
    "    seq_output = note_events[i+seq_length]\n",
    "    data_input.append([note_to_int[note] for note in seq_input])\n",
    "    data_output.append(note_to_int[seq_output])\n",
    "num_seqs = len(data_input)\n",
    "print(\"{} sequences\".format(num_seqs))\n",
    "print(\"{} ==> {}\".format(data_input[0], data_output[0]))\n",
    "data_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape input sequences into form [samples, time steps, features]\n",
    "X = np.reshape(data_input, (num_seqs, seq_length, 1))\n",
    "\n",
    "# Normalize to 0-1 range\n",
    "X = X / float(num_unique_notes)\n",
    "\n",
    "# Convert output to one-hot encoding\n",
    "y = keras.utils.np_utils.to_categorical(data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12876712]\n",
      " [ 0.11232877]\n",
      " [ 0.11780822]\n",
      " [ 0.12328767]\n",
      " [ 0.20273973]\n",
      " [ 0.29863014]\n",
      " [ 0.21917808]\n",
      " [ 0.26849315]\n",
      " [ 0.21369863]\n",
      " [ 0.11506849]]\n",
      "==>\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(\"==>\")\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X.shape = (625, 10, 1), y.shape = (625, 365)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remembering what our shape is\n",
    "\"X.shape = {}, y.shape = {}\".format(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.LSTM(256))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(y.shape[1], activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup checkpoints\n",
    "curr_datetime = str(datetime.datetime.now())\n",
    "curr_datetime = re.sub(\"\\W+\", \"\", curr_datetime)\n",
    "checkpoint_path = \"weights_\" + str(tune_name) + \"_\" + str(curr_datetime) + \"_{epoch:02d}_{loss:.4f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor=\"loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up model fit parameters\n",
    "# TODO: Play with these parameters, of course\n",
    "num_epochs = 200\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not fitting model; we'll use existing weights for ColemanHawkins_BodyAndSoul_FINAL instead\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (i.e. train the network)!\n",
    "if should_fit_model:\n",
    "    model.fit(X, y, epochs=num_epochs, batch_size=batch_size, callbacks=callbacks)\n",
    "else:\n",
    "    print(\"Not fitting model; we'll use existing weights for {} instead\".format(tune_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate output notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColemanHawkins_BodyAndSoul_FINAL_20170702124647869274_99_0.8517\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 256)           264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 365)               93805     \n",
      "=================================================================\n",
      "Total params: 883,309\n",
      "Trainable params: 883,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load network weights and recompile (if we didn't already fit the model)\n",
    "# NOTE: Make sure these weights fit the model that has been defined\n",
    "\n",
    "if not should_fit_model:\n",
    "    # Anthropology - Art Pepper\n",
    "    # weights_filename = \"weights_99_0.9724.hdf5\" # Using only note ons\n",
    "    # weights_filename = \"weights_99_1.3571.hdf5\" # Using both note ons and note offs\n",
    "    # weights_filename = \"weights_95_1.4241.hdf5\" # Using note on/off pairs\n",
    "    # weights_filename = \"weights_97_1.4300.hdf5\" # Using note on/off pairs without note off velocity\n",
    "    \n",
    "    # Body and Soul - Coleman Hawkins\n",
    "    weights_filename = \"weights_ColemanHawkins_BodyAndSoul_FINAL_20170702124647869274_00_5.8874.hdf5\" # 1 epoch\n",
    "    weights_filename = \"weights_ColemanHawkins_BodyAndSoul_FINAL_20170702124647869274_09_5.4606.hdf5\" # 10 epochs\n",
    "    weights_filename = \"weights_ColemanHawkins_BodyAndSoul_FINAL_20170702124647869274_49_2.3032.hdf5\" # 50 epochs\n",
    "    weights_filename = \"weights_ColemanHawkins_BodyAndSoul_FINAL_20170702124647869274_99_0.8517.hdf5\" # 100 epochs\n",
    "    #weights_filename = \"weights_ColemanHawkins_BodyAndSoul_FINAL_20170702132955060412_189_0.2080.hdf5\" # 200 epochs\n",
    "    #weights_filename = \"weights_ColemanHawkins_BodyAndSoul_FINAL_20170702132955060412_452_0.0212.hdf5\" # 500 epochs\n",
    "\n",
    "#     # Oleo - John Coltrane\n",
    "#     weights_filename = \"weights_JohnColtrane_Oleo_FINAL_20170702100647144230_00_5.5314.hdf5\" # 1 epoch\n",
    "#     weights_filename = \"weights_JohnColtrane_Oleo_FINAL_20170702100647144230_09_5.0914.hdf5\" # 10 epochs\n",
    "#     weights_filename = \"weights_JohnColtrane_Oleo_FINAL_20170702100647144230_49_3.0890.hdf5\" # 50 epochs\n",
    "#     weights_filename = \"weights_JohnColtrane_Oleo_FINAL_20170702100647144230_99_1.0946.hdf5\" # 100 epochs\n",
    "#     # weights_filename = \"weights_JohnColtrane_Oleo_FINAL_20170702100647144230_195_0.2916.hdf5\" # 200 epochs\n",
    "#     # weights_filename = \"weights_JohnColtrane_Oleo_FINAL_20170702100647144230_347_0.1016.hdf5\" # 350 epochs\n",
    "\n",
    "#     # Oleo - Miles Davis\n",
    "#     weights_filename = \"weights_MilesDavis_Oleo-1_FINAL_20170702105943022387_00_4.9016.hdf5\" # 1 epoch\n",
    "#     weights_filename = \"weights_MilesDavis_Oleo-1_FINAL_20170702105943022387_09_4.6219.hdf5\" # 10 epochs\n",
    "#     weights_filename = \"weights_MilesDavis_Oleo-1_FINAL_20170702105943022387_48_2.3996.hdf5\" # 50 epochs\n",
    "# #     weights_filename = \"weights_MilesDavis_Oleo-1_FINAL_20170702105943022387_96_1.1572.hdf5\" # 100 epochs\n",
    "    \n",
    "#     # Oleo - Red Garland\n",
    "# #     weights_filename = \"weights_RedGarland_Oleo_FINAL_20170702110744825363_00_5.2685.hdf5\" # 1 epoch\n",
    "# #     weights_filename = \"weights_RedGarland_Oleo_FINAL_20170702110744825363_09_4.8339.hdf5\" # 10 epochs\n",
    "# #     weights_filename = \"weights_RedGarland_Oleo_FINAL_20170702110744825363_48_2.6569.hdf5\" # 50 epochs\n",
    "# #     weights_filename = \"weights_RedGarland_Oleo_FINAL_20170702110744825363_98_1.1915.hdf5\" # 100 epochs\n",
    "\n",
    "\n",
    "    # Update tune name\n",
    "    tune_name = weights_filename.replace(\"weights_\", \"\").replace(\".hdf5\", \"\")\n",
    "    #re.sub(\"_\\d+_\\d+_\\d+\\.\\d+\\.hdf5\", \"\", tune_name)\n",
    "    #tune_name = re.sub(\"FINAL_\\d+\", \"FINAL\", tune_name)\n",
    "\n",
    "    model.load_weights(weights_filename)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "# Print out a summary of the model\n",
    "print(tune_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57, 90, 0, 6930),\n",
       " (54, 100, 0, 6930),\n",
       " (49, 80, 0, 6930),\n",
       " (50, 80, 0, 6930),\n",
       " (54, 100, 0, 6930),\n",
       " (56, 90, 0, 6930),\n",
       " (53, 70, 0, 34650),\n",
       " (56, 110, 0, 6930),\n",
       " (59, 100, 0, 6930),\n",
       " (62, 110, 0, 6930)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with a random seed\n",
    "seq_in = data_input[np.random.randint(num_seqs)]\n",
    "# seq_in = data_input[0][:10] # Force seed to first seq\n",
    "# seq_in = [18,18,18,18,18,18,18,18,18,18]\n",
    "[int_to_note[i] for i in seq_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noteoff_time': 6930,\n",
       " 'noteon_pitch': 57,\n",
       " 'noteon_time': 0,\n",
       " 'noteon_velocity': 90}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_in_notes = [int_to_note[i] for i in seq_in]\n",
    "[dict((note_events_keys[i], note[i]) for i,_ in enumerate(note)) for note in seq_in_notes][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57, 90, 0, 6930),\n",
       " (54, 100, 0, 6930),\n",
       " (49, 80, 0, 6930),\n",
       " (50, 80, 0, 6930),\n",
       " (54, 100, 0, 6930),\n",
       " (56, 90, 0, 6930),\n",
       " (53, 70, 0, 34650),\n",
       " (56, 110, 0, 6930),\n",
       " (59, 100, 0, 6930),\n",
       " (62, 110, 0, 6930),\n",
       " (65, 100, 0, 6930),\n",
       " (62, 110, 0, 6930),\n",
       " (59, 90, 0, 6930),\n",
       " (56, 100, 0, 6930),\n",
       " (53, 90, 0, 6930),\n",
       " (50, 90, 0, 6930),\n",
       " (53, 80, 0, 6930),\n",
       " (63, 100, 0, 6930),\n",
       " (66, 90, 0, 6930),\n",
       " (63, 100, 0, 6930)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the notes!\n",
    "num_notes_to_generate = 100\n",
    "notes_out = []\n",
    "notes_out.extend(seq_in_notes) # Add first sequence to output\n",
    "\n",
    "for i in range(num_notes_to_generate):\n",
    "    # Reshape and normalize\n",
    "    x = np.reshape(seq_in, (1, len(seq_in), 1)) # Reshape\n",
    "    x = x / float(num_unique_notes) # Normalize\n",
    "    \n",
    "    # Make the prediction\n",
    "    pred = model.predict(x, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Get output note\n",
    "    note_idx = np.argmax(pred)\n",
    "    note = int_to_note[note_idx]\n",
    "    \n",
    "    # Add output note to list\n",
    "    notes_out.append(note)\n",
    "    \n",
    "    # Add output note to input sequence, and move forward by one note\n",
    "    seq_in.append(note_idx) \n",
    "    seq_in = seq_in[1:len(seq_in)]\n",
    "\n",
    "notes_out[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_on channel=0 note=57 velocity=90 time=0\n",
      "note_off channel=0 note=57 velocity=90 time=138\n",
      "note_on channel=0 note=54 velocity=100 time=0\n",
      "note_off channel=0 note=54 velocity=100 time=138\n",
      "note_on channel=0 note=49 velocity=80 time=0\n",
      "note_off channel=0 note=49 velocity=80 time=138\n",
      "note_on channel=0 note=50 velocity=80 time=0\n",
      "note_off channel=0 note=50 velocity=80 time=138\n",
      "note_on channel=0 note=54 velocity=100 time=0\n",
      "note_off channel=0 note=54 velocity=100 time=138\n",
      "note_on channel=0 note=56 velocity=90 time=0\n",
      "note_off channel=0 note=56 velocity=90 time=138\n",
      "note_on channel=0 note=53 velocity=70 time=0\n",
      "note_off channel=0 note=53 velocity=70 time=693\n",
      "note_on channel=0 note=56 velocity=110 time=0\n",
      "note_off channel=0 note=56 velocity=110 time=138\n"
     ]
    }
   ],
   "source": [
    "# Convert the sequence of note tuples into a sequence of MIDI notes, and then write to MIDI file\n",
    "\n",
    "# Create MIDI file and track\n",
    "midi_file_out = mido.MidiFile()\n",
    "midi_track_out = mido.MidiTrack()\n",
    "midi_file_out.tracks.append(midi_track_out)\n",
    "\n",
    "# Append \"headers\" (track name, tempo, key, time signature)\n",
    "for message in midi_track[:4]:\n",
    "    midi_track_out.append(message)\n",
    "\n",
    "# Add notes\n",
    "prev_time = 0\n",
    "prev_note = 0\n",
    "\n",
    "# Note times get all bunched together, so we stretch them out a little bit manually here...\n",
    "time_multiplier = 2 # Art Pepper - Anthropology\n",
    "time_multiplier = 0.02 # Coleman Hawkins - Body and Soul\n",
    "\n",
    "for note in notes_out:\n",
    "    ## Note ons only\n",
    "    #curr_time = prev_time + note[2]\n",
    "    #prev_note = note[0]\n",
    "    #prev_time = curr_time\n",
    "    #message_noteoff = mido.Message(\"note_off\", note=prev_note, velocity=0, time=curr_time) # Prev note off\n",
    "    #message_noteon = mido.Message(\"note_on\", note=note[0], velocity=note[1], time=curr_time) # Curr note on\n",
    "    #midi_track_out.append(message_noteoff)\n",
    "    #midi_track_out.append(message_noteon)\n",
    "    \n",
    "    ## Note ons and note offs \n",
    "    #curr_time = prev_time + note[3] if note[0]==\"note_on\" else prev_time\n",
    "    #curr_time = prev_time + note[3]\n",
    "    #prev_time = curr_time\n",
    "    #message = mido.Message(note[0], note=note[1], velocity=note[2], time=curr_time)\n",
    "    #midi_track_out.append(message)\n",
    "    \n",
    "    # Note on/off pairs\n",
    "    note = dict((note_events_keys[i], note[i]) for i,_ in enumerate(note))\n",
    "    curr_time_noteon = prev_time + int(note[\"noteon_time\"] * time_multiplier)\n",
    "    curr_time_noteoff = prev_time + int(note[\"noteoff_time\"] * time_multiplier)\n",
    "    #prev_time = curr_time_noteoff\n",
    "    message_noteon = mido.Message(\"note_on\", note=note[\"noteon_pitch\"], velocity=note[\"noteon_velocity\"], time=curr_time_noteon)\n",
    "    message_noteoff = mido.Message(\"note_off\", note=note[\"noteon_pitch\"], velocity=note[\"noteon_velocity\"], time=curr_time_noteoff)\n",
    "    midi_track_out.append(message_noteon)\n",
    "    midi_track_out.append(message_noteoff)\n",
    "    \n",
    "# Save file to disk\n",
    "curr_datetime = str(datetime.datetime.now())\n",
    "curr_datetime = re.sub(\"\\W+\", \"\", curr_datetime)\n",
    "filename_out = \"../data/out_{}_{}.mid\".format(tune_name, curr_datetime)\n",
    "midi_file_out.save(filename_out)\n",
    "\n",
    "for message in midi_track_out[4:20]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Art Pepper - Anthropology as the input melody, with random seed:\n",
    "- 100 epochs: https://soundcloud.com/usdivad/jazz-ai-experiments-lstm-single-melody-100-epochs\n",
    "\n",
    "Using Coleman Hawkins - Body and Soul as the input melody, seeded with first 10 notes of original sequence:\n",
    "- 1 epoch: https://soundcloud.com/usdivad/jazz-ai-experiments-lstm-single-melody-coleman-hawkins-body-and-soul-1-epoch\n",
    "- 10 epochs: https://soundcloud.com/usdivad/jazz-ai-experiments-lstm-single-melody-coleman-hawkins-body-and-soul-10-epochs\n",
    "- 50 epochs: https://soundcloud.com/usdivad/jazz-ai-experiments-lstm-single-melody-coleman-hawkins-body-and-soul-50-epochs\n",
    "- 100 epochs: https://soundcloud.com/usdivad/jazz-ai-experiments-lstm-single-melody-coleman-hawkins-body-and-soul-100-epochs\n",
    "- 200 epochs: https://soundcloud.com/usdivad/jazz-ai-experiments-lstm-single-melody-coleman-hawkins-body-and-soul-200-epochs\n",
    "- 500 epochs: https://soundcloud.com/usdivad/jazz-ai-experiments-lstm-single-melody-coleman-hawkins-body-and-soul-500-epochs\n",
    "\n",
    "\n",
    "You can hear a clear progression of improvement as the model is better able to represent the melodic attributes of the solo as epochs increase, until around 200 epochs where it begins overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
